{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M_8JEgCyzK3"
      },
      "outputs": [],
      "source": [
        "%%writefile Parallel.cu\n",
        "#include <stdio.h>\n",
        "#include <malloc.h>\n",
        "#include <cuda.h>\n",
        "#define Nx 16\n",
        "#define Ny 16\n",
        "#define Nt 21\n",
        "#define dxy 0.1\n",
        "#define dt 0.01\n",
        "#define GridSize 1\n",
        "#define BlockSize 8\n",
        "#define ThreadSize Nx*Ny/(GridSize*BlockSize)\n",
        "//==============================\n",
        "float funct1(int i, int j) {\n",
        "  return sin(M_PI*(i*dxy + j*dxy));\n",
        "}\n",
        "float funct2(int i, int j) {\n",
        "  return cos(M_PI*(i*dxy + j*dxy));\n",
        "}\n",
        "//==============================\n",
        "void InputData(float *U, float *V, float *C) {\n",
        "  int i,j,k;\n",
        "  for (j=0; j<Ny; j++) {\n",
        "    for (i=0; i<Nx; i++) {\n",
        "      *(U + j*Nx + i) = funct1(i,j);\n",
        "      *(V + j*Nx + i) = dt*funct2(i,j) + *(U + j*Nx + i);\n",
        "    }\n",
        "  }\n",
        "  for (k=0; k<Nt; k++) {\n",
        "    *(C+k) = 1/2;\n",
        "  }\n",
        "}\n",
        "//===========================\n",
        "__global__ void Computing(float *U, float *V, float *C){\n",
        "  float left, right, bottom, top, center1, center2;\n",
        "  int k, l, index, start, stop, nt_half;\n",
        "  index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  start = index*ThreadSize;\n",
        "  stop  = start + ThreadSize;\n",
        "  nt_half = (Nt+1)/2;\n",
        "  for (k=1; k<nt_half; k++) {\n",
        "    for (l=start; l<stop; l++) {\n",
        "      left  =  (l%Nx == 0)       ? 0 : *(U + l - 1);\n",
        "      right =  (l%Nx == Nx-1)    ? 0 : *(U + l + 1);\n",
        "      bottom = (l >= Nx*(Ny-1))  ? 0 : *(U + l - Nx);\n",
        "      top   =  (l <= Nx-1)       ? 0 : *(U + l + Nx);\n",
        "      center1 = *(V + l);\n",
        "      center2 = *(U + l);\n",
        "      *(U + l) = 2*center1 - center2 + ((dt * dt * (*(C + k)) * (*(C + k))) / (dxy * dxy)) * (left + right + bottom + top - 4*center1);\n",
        "    }\n",
        "    __syncthreads();\n",
        "    for (l=start; l<stop; l++) {\n",
        "      left  =  (l%Nx == 0)       ? 0 : *(V + l - 1);\n",
        "      right =  (l%Nx == Nx-1)    ? 0 : *(V + l + 1);\n",
        "      bottom = (l >= Nx*(Ny-1))  ? 0 : *(V + l + Nx);\n",
        "      top   =  (l <= Nx-1)       ? 0 : *(V + l - Nx);\n",
        "      center1 = *(U + l);\n",
        "      center2 = *(V + l);\n",
        "      *(V + l) = 2*center1 - center2 + ((dt * dt * (*(C + k)) * (*(C + k))) / (dxy * dxy)) * (left + right + bottom + top - 4*center1);\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "}\n",
        "//===========================\n",
        "int main() {\n",
        "  float *UCPU, *VCPU, *CCPU;\n",
        "  UCPU = (float *) malloc (Nx*Ny*sizeof(float));\n",
        "  VCPU = (float *) malloc (Nx*Ny*sizeof(float));\n",
        "  CCPU = (float *) malloc (Nt*sizeof(float));\n",
        "  InputData(UCPU, VCPU, CCPU);\n",
        "\n",
        "  // Delare and Allocate Mem on GPU\n",
        "  float *UGPU, *VGPU, *CGPU;\n",
        "  cudaMalloc((void**)&UGPU ,Nx*Ny*sizeof(float));\n",
        "  cudaMalloc((void**)&VGPU ,Nx*Ny*sizeof(float));\n",
        "  cudaMalloc((void**)&CGPU ,Nt*sizeof(float));\n",
        "\n",
        "  // Copy Input from CPU to GPU\n",
        "  cudaMemcpy(UGPU,UCPU,Nx*Ny*sizeof(float),cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(VGPU,VCPU,Nx*Ny*sizeof(float),cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(CGPU,CCPU,Nt*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "  //Define Block and Thread Structure\n",
        "  dim3 dimGrid(GridSize);\n",
        "  dim3 dimBlock(BlockSize);\n",
        "\n",
        "  //Computing\n",
        "  Computing<<<dimGrid,dimBlock>>>(UGPU, VGPU, CGPU);\n",
        "\n",
        "  //Copy Output from GPU to CPU\n",
        "  cudaMemcpy(UCPU, UGPU, Nx*Ny*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(VCPU, VGPU, Nx*Ny*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(CCPU, CGPU, Nt*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  //Show result\n",
        "  if (Nt%2 == 1) {\n",
        "    for (int j=0; j<Ny; j++) {\n",
        "      for (int i=0; i<Nx; i++) {\n",
        "        printf(\"%f \", *(UCPU + j*Nx +i));\n",
        "      }\n",
        "    printf(\"\\n\");\n",
        "    }\n",
        "  }\n",
        "  else {\n",
        "    for (int j=0; j<Ny; j++) {\n",
        "      for (int i=0; i<Nx; i++) {\n",
        "        printf(\"%f \", *(VCPU + j*Nx +i));\n",
        "      }\n",
        "    printf(\"\\n\");\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // Free Mem on CPU and GPU\n",
        "  free(UCPU); free(VCPU); free(CCPU);\n",
        "  cudaFree(UGPU); cudaFree(VGPU); cudaFree(CGPU);\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cDBo4T6p2hxB"
      },
      "outputs": [],
      "source": [
        "!nvcc Parallel.cu -lm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7XYnOHZ2jIA"
      },
      "outputs": [],
      "source": [
        "!./a.out"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}